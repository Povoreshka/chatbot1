"""
RAG –ß–∞—Ç-–±–æ—Ç –ø–æ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞–º
–ó–∞–ø—É—Å–∫: python rag_chatbot.py
"""

import os
import sys
import subprocess
from typing import List
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫
def check_and_install_dependencies():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Ö –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
    
    required_packages = [
        'langchain',
        'langchain-community',
        'chromadb',
        'pypdf',
        'sentence-transformers'
    ]
    
    missing_packages = []
    
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫...")
    
    for package in required_packages:
        package_import = package.replace('-', '_')
        try:
            __import__(package_import)
            print(f"   ‚úÖ {package} —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        except ImportError:
            print(f"   ‚ùå {package} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            missing_packages.append(package)
    
    if missing_packages:
        print(f"\nüì¶ –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {', '.join(missing_packages)}")
        for package in missing_packages:
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package])
                print(f"   ‚úÖ {package} —É—Å–ø–µ—à–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            except subprocess.CalledProcessError as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ {package}: {e}")
                return False
    
    return True

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø–µ—Ä–µ–¥ –∏–º–ø–æ—Ä—Ç–æ–º
if not check_and_install_dependencies():
    print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏—Ö –≤—Ä—É—á–Ω—É—é:")
    print("pip install langchain langchain-community chromadb pypdf sentence-transformers")
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
    sys.exit(1)

# –¢–µ–ø–µ—Ä—å –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏
try:
    from langchain_community.document_loaders import PyPDFLoader
    from langchain_community.embeddings import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    
    # –í –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö LangChain Document –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ langchain_core
    try:
        from langchain_core.documents import Document
        print("‚úÖ –ò–º–ø–æ—Ä—Ç Document –∏–∑ langchain_core.documents")
    except ImportError:
        try:
            from langchain.schema import Document
            print("‚úÖ –ò–º–ø–æ—Ä—Ç Document –∏–∑ langchain.schema")
        except ImportError:
            # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–π –∫–ª–∞—Å—Å Document –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
            class Document:
                def __init__(self, page_content="", metadata=None):
                    self.page_content = page_content
                    self.metadata = metadata or {}
            print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å Document")
    
    # –í –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏—è—Ö text_splitter –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
    try:
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        print("‚úÖ –ò–º–ø–æ—Ä—Ç text_splitter –∏–∑ langchain.text_splitter")
    except ImportError:
        try:
            from langchain_community.text_splitter import RecursiveCharacterTextSplitter
            print("‚úÖ –ò–º–ø–æ—Ä—Ç text_splitter –∏–∑ langchain_community.text_splitter")
        except ImportError:
            try:
                from langchain_text_splitters import RecursiveCharacterTextSplitter
                print("‚úÖ –ò–º–ø–æ—Ä—Ç text_splitter –∏–∑ langchain_text_splitters")
            except ImportError:
                # –°–≤–æ–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–ª–∏—Ç—Ç–µ—Ä
                class RecursiveCharacterTextSplitter:
                    def __init__(self, chunk_size=500, chunk_overlap=50, separators=None, length_function=len):
                        self.chunk_size = chunk_size
                        self.chunk_overlap = chunk_overlap
                        self.separators = separators or ["\n\n", "\n", ".", "!", "?", ",", " ", ""]
                        self.length_function = length_function
                    
                    def split_documents(self, documents):
                        chunks = []
                        for doc in documents:
                            text = doc.page_content
                            # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
                            for i in range(0, len(text), self.chunk_size - self.chunk_overlap):
                                chunk_text = text[i:i + self.chunk_size]
                                if chunk_text:
                                    chunks.append(Document(
                                        page_content=chunk_text,
                                        metadata=doc.metadata
                                    ))
                        return chunks
                
                print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π —Å–ø–ª–∏—Ç—Ç–µ—Ä")
    
    print("\n‚úÖ –í—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    
except ImportError as e:
    print(f"\n‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("\n–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∫–æ–º–∞–Ω–¥—É:")
    print("pip install --upgrade langchain langchain-community langchain-core")
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
    sys.exit(1)

@dataclass
class ChunkInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —á–∞–Ω–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    text: str
    page: int
    source: str
    relevance_score: float = 0.0

class SimpleRAGBot:
    """–ü—Ä–æ—Å—Ç–æ–π RAG –±–æ—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –∫–æ–Ω—Å–ø–µ–∫—Ç–∞–º–∏"""
    
    def __init__(self, persist_directory: str = "./chroma_db"):
        self.persist_directory = persist_directory
        print("\nüîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
        
        try:
            self.embeddings = HuggingFaceEmbeddings(
                model_name="sentence-transformers/all-MiniLM-L6-v2",
                model_kwargs={'device': 'cpu'}
            )
            print("‚úÖ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
        
        self.vector_store = None
        self.chunks_count = 0
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ë–î
        self._load_existing_db()
    
    def _load_existing_db(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        if os.path.exists(self.persist_directory):
            try:
                print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
                self.vector_store = Chroma(
                    persist_directory=self.persist_directory,
                    embedding_function=self.embeddings
                )
                # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤
                self.chunks_count = len(self.vector_store.get()['ids'])
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –ë–î —Å {self.chunks_count} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞–º–∏")
                return True
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ë–î: {e}")
                return False
        return False
    
    def process_pdf(self, pdf_path: str) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —Ñ–∞–π–ª–∞"""
        if not os.path.exists(pdf_path):
            print(f"‚ùå –§–∞–π–ª {pdf_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        print(f"\nüìÑ –ó–∞–≥—Ä—É–∂–∞–µ–º PDF: {pdf_path}")
        
        try:
            # –ó–∞–≥—Ä—É–∑–∫–∞ PDF
            loader = PyPDFLoader(pdf_path)
            documents = loader.load()
            print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} —Å—Ç—Ä–∞–Ω–∏—Ü")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
            for i, doc in enumerate(documents):
                doc.metadata["page"] = i + 1
                doc.metadata["source"] = os.path.basename(pdf_path)
            
            # –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,
                separators=["\n\n", "\n", ".", "!", "?", ",", " ", ""],
                length_function=len
            )
            
            chunks = text_splitter.split_documents(documents)
            print(f"   ‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
            print("üîÑ –°–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ...")
            self.vector_store = Chroma.from_documents(
                documents=chunks,
                embedding=self.embeddings,
                persist_directory=self.persist_directory
            )
            self.vector_store.persist()
            self.chunks_count = len(chunks)
            
            print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {self.persist_directory}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ PDF: {e}")
            return False
    
    def search(self, query: str, k: int = 3) -> List[ChunkInfo]:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤"""
        if not self.vector_store:
            print("‚ùå –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ PDF!")
            return []
        
        try:
            # –ü–æ–∏—Å–∫ —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å—é
            results = self.vector_store.similarity_search_with_relevance_scores(query, k=k)
            
            chunks = []
            for doc, score in results:
                chunks.append(ChunkInfo(
                    text=doc.page_content,
                    page=doc.metadata.get('page', 0),
                    source=doc.metadata.get('source', 'unknown'),
                    relevance_score=score
                ))
            
            return chunks
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
    
    def generate_answer(self, question: str, chunks: List[ChunkInfo]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤"""
        if not chunks:
            return "‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É."
        
        answer = []
        answer.append(f"\n{'='*60}")
        answer.append(f"üìù –í–æ–ø—Ä–æ—Å: {question}")
        answer.append(f"{'='*60}\n")
        
        answer.append("üîç –ù–∞–π–¥–µ–Ω–∞ —Å–ª–µ–¥—É—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n")
        
        for i, chunk in enumerate(chunks, 1):
            answer.append(f"\n--- –ò—Å—Ç–æ—á–Ω–∏–∫ {i} (–°—Ç—Ä–∞–Ω–∏—Ü–∞ {chunk.page}) ---")
            answer.append(f"üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {chunk.relevance_score:.3f}")
            # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            text_preview = chunk.text[:300] + "..." if len(chunk.text) > 300 else chunk.text
            answer.append(f"üìÑ –¢–µ–∫—Å—Ç: {text_preview}")
            answer.append("-" * 40)
        
        return "\n".join(answer)

def clear_screen():
    """–û—á–∏—Å—Ç–∫–∞ —ç–∫—Ä–∞–Ω–∞"""
    os.system('cls' if os.name == 'nt' else 'clear')

def print_menu():
    """–í—ã–≤–æ–¥ –º–µ–Ω—é"""
    print("\n" + "="*60)
    print("üìö RAG –ß–∞—Ç-–±–æ—Ç –ø–æ –∫–æ–Ω—Å–ø–µ–∫—Ç–∞–º")
    print("="*60)
    print("1. üìÅ –ó–∞–≥—Ä—É–∑–∏—Ç—å/–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF")
    print("2. ‚ùì –ó–∞–¥–∞—Ç—å –≤–æ–ø—Ä–æ—Å")
    print("3. üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    print("4. üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
    print("5. üö™ –í—ã—Ö–æ–¥")
    print("="*60)

def find_pdf_files():
    """–ü–æ–∏—Å–∫ PDF —Ñ–∞–π–ª–æ–≤ –≤ —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
    pdf_files = [f for f in os.listdir('.') if f.lower().endswith('.pdf')]
    return pdf_files

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    clear_screen()
    print("="*60)
    print("üöÄ –ó–ê–ü–£–°–ö RAG –ß–ê–¢-–ë–û–¢–ê")
    print("="*60)
    
    try:
        bot = SimpleRAGBot()
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
        return
    
    while True:
        clear_screen()
        print_menu()
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ PDF —Ñ–∞–π–ª—ã
        pdf_files = find_pdf_files()
        if pdf_files:
            print("\nüìÅ –ù–∞–π–¥–µ–Ω–Ω—ã–µ PDF –≤ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ:")
            for i, pdf in enumerate(pdf_files, 1):
                size = os.path.getsize(pdf) / 1024  # —Ä–∞–∑–º–µ—Ä –≤ –ö–ë
                print(f"   {i}. {pdf} ({size:.1f} KB)")
        else:
            print("\nüìÅ PDF —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–µ")
            print("   –ü–æ–ª–æ–∂–∏—Ç–µ PDF —Ñ–∞–π–ª –≤ —ç—Ç—É –ø–∞–ø–∫—É –∏ –≤—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç 1")
        
        print("\n" + "-"*60)
        choice = input("üîπ –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (1-5): ").strip()
        
        if choice == '1':
            clear_screen()
            print("üìÅ –ó–ê–ì–†–£–ó–ö–ê PDF\n")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å PDF —Ñ–∞–π–ª—ã, –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º –≤—ã–±—Ä–∞—Ç—å
            if pdf_files:
                print("–î–æ—Å—Ç—É–ø–Ω—ã–µ PDF —Ñ–∞–π–ª—ã:")
                for i, pdf in enumerate(pdf_files, 1):
                    size = os.path.getsize(pdf) / 1024
                    print(f"{i}. {pdf} ({size:.1f} KB)")
                print("0. –£–∫–∞–∑–∞—Ç—å —Å–≤–æ–π –ø—É—Ç—å")
                
                file_choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞: ").strip()
                
                if file_choice.isdigit():
                    idx = int(file_choice)
                    if 1 <= idx <= len(pdf_files):
                        pdf_path = pdf_files[idx-1]
                        print(f"‚úÖ –í—ã–±—Ä–∞–Ω —Ñ–∞–π–ª: {pdf_path}")
                    else:
                        pdf_path = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É: ").strip()
                else:
                    pdf_path = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É: ").strip()
            else:
                pdf_path = input("–í–≤–µ–¥–∏—Ç–µ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É: ").strip()
            
            if pdf_path and pdf_path.lower() != 'exit':
                bot.process_pdf(pdf_path)
            
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        
        elif choice == '2':
            clear_screen()
            print("‚ùì –ó–ê–î–ê–¢–¨ –í–û–ü–†–û–°\n")
            
            if bot.chunks_count == 0:
                print("‚ö†Ô∏è –°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ PDF —Ñ–∞–π–ª!")
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
                continue
            
            question = input("–í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            
            if question and question.lower() != 'exit':
                print("\nüîç –ò—â–µ–º –æ—Ç–≤–µ—Ç...")
                chunks = bot.search(question)
                answer = bot.generate_answer(question, chunks)
                print(answer)
            
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        
        elif choice == '3':
            clear_screen()
            print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê\n")
            print(f"üìÅ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö: {bot.persist_directory}")
            print(f"üìä –§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≤ –ë–î: {bot.chunks_count}")
            print(f"ü§ñ –ú–æ–¥–µ–ª—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: all-MiniLM-L6-v2")
            
            if bot.vector_store:
                print("‚úÖ –°—Ç–∞—Ç—É—Å: –ê–∫—Ç–∏–≤–Ω–∞")
            else:
                print("‚ùå –°—Ç–∞—Ç—É—Å: –ù–µ –∞–∫—Ç–∏–≤–Ω–∞ (–∑–∞–≥—Ä—É–∑–∏—Ç–µ PDF)")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
            if os.path.exists(bot.persist_directory):
                import shutil
                size = sum(os.path.getsize(os.path.join(dirpath, filename)) 
                          for dirpath, _, filenames in os.walk(bot.persist_directory) 
                          for filename in filenames) / 1024 / 1024  # –≤ –ú–ë
                print(f"üíæ –†–∞–∑–º–µ—Ä –ë–î: {size:.2f} MB")
            
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        
        elif choice == '4':
            clear_screen()
            print("üóëÔ∏è –û–ß–ò–°–¢–ö–ê –ë–ê–ó–´ –î–ê–ù–ù–´–•\n")
            
            confirm = input("–í—ã —É–≤–µ—Ä–µ–Ω—ã? –í—Å–µ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã! (–¥–∞/–Ω–µ—Ç): ").strip().lower()
            
            if confirm in ['–¥–∞', 'yes', 'y', '–¥–∞']:
                import shutil
                if os.path.exists(bot.persist_directory):
                    shutil.rmtree(bot.persist_directory)
                    bot.vector_store = None
                    bot.chunks_count = 0
                    print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—á–∏—â–µ–Ω–∞")
                else:
                    print("‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
        
        elif choice == '5':
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        
        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä! –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ –æ—Ç 1 –¥–æ 5")
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nüëã –ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n‚ùå –ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")